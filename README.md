# Lexify Research Assistant

An AI-powered research assistant that helps users discover, analyze, and interact with academic papers through intelligent search, summarization, and conversational AI using advanced RAG (Retrieval-Augmented Generation) technology.

![Lexify Research Assistant](https://img.shields.io/badge/Vue.js-3.x-green) ![Flask](https://img.shields.io/badge/Flask-2.x-blue) ![Python](https://img.shields.io/badge/Python-3.9+-yellow) ![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue) ![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-purple) ![LiteLLM](https://img.shields.io/badge/LiteLLM-Multi_Provider-orange)

## ğŸš€ Features

### ğŸ“Š Research Discovery
- **ArXiv Integration**: Direct search and retrieval from ArXiv academic papers
- **Smart Summarization**: AI-generated individual paper summaries and consolidated insights
- **Advanced Filtering**: Filter by publication date, categories, and relevance
- **Automatic Processing**: Background PDF download, text extraction, and vector indexing

### ğŸ’¬ Intelligent Chat Interface
- **Conversational RAG**: Ask questions about selected research papers using context-aware AI
- **Multi-Paper Analysis**: Chat with multiple papers simultaneously for comparative analysis
- **Source Citations**: Every response includes precise references to source materials
- **Session Management**: Persistent chat sessions with full conversation history

### ğŸ” RAG-Powered Analysis
- **Vector Search**: Semantic search through paper content using Qdrant embeddings
- **Context Retrieval**: Intelligent chunk selection based on query relevance
- **Citation Tracking**: Inline citations with clickable paper references
- **Real-time Processing**: Papers are processed asynchronously for immediate chat availability

### ğŸ‘¤ User Management
- **JWT Authentication**: Secure user registration and login system
- **Personal Library**: Organize and manage your research papers
- **Chat History**: Access and resume previous research conversations
- **Cross-Session Persistence**: Continue research across multiple sessions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   External      â”‚
â”‚   (Vue 3 + TS)  â”‚    â”‚   (Flask)       â”‚    â”‚   Services      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Vue Router    â”‚    â”‚ â€¢ REST API      â”‚    â”‚ â€¢ ArXiv API     â”‚
â”‚ â€¢ Pinia Store   â”‚â—„â”€â”€â–ºâ”‚ â€¢ SQLAlchemy    â”‚â—„â”€â”€â–ºâ”‚ â€¢ LiteLLM       â”‚
â”‚ â€¢ Tailwind CSS  â”‚    â”‚ â€¢ JWT Auth      â”‚    â”‚ â€¢ Qdrant Cloud  â”‚
â”‚ â€¢ TypeScript    â”‚    â”‚ â€¢ RAG Pipeline  â”‚    â”‚ â€¢ Gemini API    â”‚
â”‚ â€¢ Responsive UI â”‚    â”‚ â€¢ Async Tasks   â”‚    â”‚ â€¢ PDF Sources   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

### Backend
- **Framework**: Flask 2.x with modular Blueprint architecture
- **Database**: SQLAlchemy ORM with PostgreSQL/MySQL/SQLite support
- **Authentication**: JWT tokens with Flask-JWT-Extended
- **AI Integration**: LiteLLM supporting multiple providers (Gemini, OpenAI, etc.)
- **Vector Database**: Qdrant Cloud for semantic search and embeddings
- **Document Processing**: PyMuPDF for PDF text extraction
- **Text Processing**: Advanced chunking and cleaning utilities
- **Async Processing**: Threading for background paper processing

### Frontend
- **Framework**: Vue 3 with Composition API and TypeScript
- **Styling**: Tailwind CSS with custom component design
- **State Management**: Pinia for reactive application state
- **Routing**: Vue Router 4 with authentication guards
- **HTTP Client**: Axios with interceptors for API communication
- **UI Components**: Custom responsive components with modern design
- **Build Tool**: Vite for fast development and optimized builds

### AI & Vector System
- **Vector Database**: Qdrant for high-performance semantic search
- **Embeddings**: Configurable embedding models via LiteLLM
- **LLM Integration**: Multi-provider support through LiteLLM
- **RAG Pipeline**: Custom context retrieval and response generation
- **Prompt Engineering**: Structured prompts for different use cases

## ğŸ“¦ Installation

### Prerequisites
- **Python 3.8+** with pip
- **Node.js 16+** with npm
- **Database** (PostgreSQL/MySQL recommended, SQLite for development)
- **Qdrant** (Cloud account or self-hosted instance)
- **LiteLLM API Keys** (Gemini, OpenAI, or other supported providers)

### Backend Setup

1. **Clone and Setup Environment**
```bash
git clone <repository-url>
cd lexify_research_assistant/backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

2. **Environment Configuration**
Create `.env` file in backend directory:
```env
# Database Configuration
DATABASE_URL=postgresql://user:password@localhost/lexify_db
# or for SQLite: sqlite:///instance/app.db

# JWT Configuration
SECRET_KEY=your-super-secret-key-here
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ACCESS_TOKEN_EXPIRES=3600

# Qdrant Configuration
QDRANT_URL=https://your-qdrant-instance.qdrant.tech
QDRANT_API_KEY=your-qdrant-api-key

# LiteLLM Configuration  
LITELLM_MODEL_SUMMARIZE=gemini/gemini-2.0-flash
LITELLM_MODEL_CHAT=gemini/gemini-2.0-flash
EMBEDDING_MODEL_NAME=gemini/text-embedding-004

# API Keys (if using specific providers)
GOOGLE_API_KEY=your-gemini-api-key
OPENAI_API_KEY=your-openai-key

# File Storage
PAPER_SAVE_DIR=data/papers
PROMPTS_DIR=prompts
```

3. **Flask Environment Setup**
Create `.flaskenv` file:
```env
FLASK_APP=run.py
FLASK_ENV=development
FLASK_DEBUG=1
```

4. **Database Initialization**
```bash
# Initialize database
flask db init
flask db migrate -m "Initial migration"
flask db upgrade
```

5. **Create Required Directories**
```bash
mkdir -p data/papers logs
```

6. **Start Backend Server**
```bash
python run.py
# Server will run on http://localhost:5000
```

### Frontend Setup

1. **Navigate and Install**
```bash
cd ../frontend
npm install
```

2. **Environment Configuration**
Create `.env.local` file:
```env
VITE_API_BASE_URL=http://localhost:5000/api
```

3. **Start Development Server**
```bash
npm run dev
# Frontend will run on http://localhost:5173
```

## ğŸš€ Usage Guide

### 1. User Registration & Authentication
```typescript
// Register new account
POST /api/auth/register
{
  "username": "researcher",
  "email": "user@example.com", 
  "password": "securepassword"
}

// Login
POST /api/auth/login
{
  "username_or_email": "researcher",
  "password": "securepassword"
}
```

### 2. Research Workflow

**Step 1: Search Papers**
- Enter research query in the search interface
- System searches ArXiv and displays results
- Individual summaries and consolidated insights are generated
- Papers are automatically queued for processing

**Step 2: Review Results**
- Browse paper summaries with metadata
- Check processing status indicators
- Select papers for interactive chat

**Step 3: Interactive Chat**
- Start conversation with selected papers
- Ask questions about methodology, findings, implications
- Receive contextually grounded responses with citations
- Access chat history from previous sessions

## ğŸ“ Project Structure

```
lexify_research_assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Flask app factory
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration classes
â”‚   â”‚   â”œâ”€â”€ extensions.py         # Flask extensions
â”‚   â”‚   â”œâ”€â”€ api/                  # API Blueprint modules
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ papers.py        # Paper search & processing
â”‚   â”‚   â”‚   â””â”€â”€ rag.py           # RAG chat endpoints
â”‚   â”‚   â”œâ”€â”€ models/               # Database models
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py          # User model
â”‚   â”‚   â”‚   â”œâ”€â”€ paper.py         # Paper metadata model
â”‚   â”‚   â”‚   â””â”€â”€ chat.py          # Chat session models
â”‚   â”‚   â”œâ”€â”€ core/                 # Business logic services
â”‚   â”‚   â”‚   â”œâ”€â”€ arxiv_service.py # ArXiv integration
â”‚   â”‚   â”‚   â”œâ”€â”€ download_service.py # PDF downloading
â”‚   â”‚   â”‚   â”œâ”€â”€ processing_service.py # Text processing
â”‚   â”‚   â”‚   â”œâ”€â”€ summarizer_service.py # Summarization
â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py   # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ utils/                # Utility modules
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever/       # Paper retrieval
â”‚   â”‚   â”‚   â”œâ”€â”€ processor/       # Text processing
â”‚   â”‚   â”‚   â”œâ”€â”€ summarizer/      # Summarization
â”‚   â”‚   â”‚   â””â”€â”€ rag/             # RAG components
â”‚   â”‚   â””â”€â”€ services/             # External services
â”‚   â”‚       â”œâ”€â”€ qdrant_client_setup.py
â”‚   â”‚       â”œâ”€â”€ litellm_service.py
â”‚   â”‚       â””â”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ prompts/                  # LLM prompt templates
â”‚   â”œâ”€â”€ data/papers/              # Downloaded PDFs
â”‚   â”œâ”€â”€ logs/                     # Application logs
â”‚   â”œâ”€â”€ migrations/               # Database migrations
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ run.py                    # Application entry point
â”‚   â””â”€â”€ .env                      # Environment variables
|
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # Vue components
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/            # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ paper/           # Paper components
â”‚   â”‚   â”‚   â””â”€â”€ layout/          # Layout components
â”‚   â”‚   â”œâ”€â”€ views/                # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginView.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ RegisterView.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ ResearchView.vue
â”‚   â”‚   â”‚   â””â”€â”€ ChatHistoryView.vue
â”‚   â”‚   â”œâ”€â”€ services/             # API service layer
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts           # Base API configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ authService.ts   # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ paperService.ts  # Paper operations
â”‚   â”‚   â”‚   â””â”€â”€ ragService.ts    # RAG operations
â”‚   â”‚   â”œâ”€â”€ store/                # Pinia stores
â”‚   â”‚   â”‚   â””â”€â”€ authStore.ts     # Authentication state
â”‚   â”‚   â”œâ”€â”€ types/                # TypeScript definitions
â”‚   â”‚   â”‚   â””â”€â”€ index.ts         # Type definitions
â”‚   â”‚   â”œâ”€â”€ router/               # Vue Router
â”‚   â”‚   â”‚   â””â”€â”€ index.ts         # Route configuration
â”‚   â”‚   â”œâ”€â”€ App.vue               # Root component
â”‚   â”‚   â””â”€â”€ main.ts               # Application entry
â”‚   â”œâ”€â”€ package.json              # Dependencies
â”‚   â”œâ”€â”€ vite.config.ts            # Vite configuration
â”‚   â”œâ”€â”€ tailwind.config.js        # Tailwind CSS config
â”‚   â””â”€â”€ .env.local                # Environment variables
â””â”€â”€ README.md
```

## ğŸ›¡ï¸ API Endpoints

### Authentication (`/api/auth`)
- `POST /register` - User registration
- `POST /login` - User login  
- `POST /logout` - User logout
- `GET /protected` - Protected route example

### Papers (`/api/papers`)
- `POST /search` - Search and summarize papers
- `GET /<id>/status` - Get paper processing status
- `POST /<id>/process-manual` - Manual processing trigger

### RAG & Chat (`/api/rag`)
- `POST /chat` - Send chat message with selected papers
- `GET /sessions` - List user's chat sessions
- `GET /sessions/<id>/messages` - Get session messages

## ğŸ”§ Key Features Implementation

### RAG Pipeline
1. **Document Processing**: PDF text extraction and cleaning
2. **Chunking**: Intelligent text segmentation for context
3. **Embedding**: Vector representation using LiteLLM
4. **Indexing**: Storage in Qdrant with metadata
5. **Retrieval**: Context-aware chunk selection
6. **Generation**: LLM response with source citations

### Chat System
- **Session Management**: Persistent conversations
- **Context Awareness**: Multi-turn dialogue support
- **Source Tracking**: Citation mapping to original papers
- **Real-time Processing**: Background paper preparation

### User Experience
- **Responsive Design**: Mobile-friendly interface
- **Progress Indicators**: Processing status feedback
- **Error Handling**: Graceful error recovery
- **Performance**: Optimized loading and caching

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Make changes with proper TypeScript/Python typing
4. Test thoroughly (backend and frontend)
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Built with â¤ï¸ for the research community**

*Empowering researchers with AI-driven paper analysis and intelligent conversation*